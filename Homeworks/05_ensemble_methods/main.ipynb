{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe52a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_validate, TimeSeriesSplit, ShuffleSplit, StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier, AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(1,100,10000) \n",
    "\n",
    "y=(np.sin(x)+np.random.rand(x.shape[0])*0.3>0.2).astype(int)\n",
    "x = x.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c7a3a",
   "metadata": {},
   "source": [
    "Так как X это у нас данные, которые представляют из себя некую последовательно, то можно сделать вывод что мы работает с упорядоченными данными. Буду применять TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b067094",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=False) #При использовании TimeSeriesSplit данные не нужно пермешивать\n",
    "# По дефолту train_test_split перемешивает данные\n",
    "cvsk = TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42c79b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучая найденная глубина: 1\n",
      "Score моей модели = 0.5052\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "best_score = 0\n",
    "for i in range(1, 100):\n",
    "  clf = tree.DecisionTreeClassifier(max_depth = i)\n",
    "  bagging_clf = BaggingClassifier(clf, n_estimators = 5)\n",
    "  res = cross_validate(bagging_clf, x_train, y_train, cv = cvsk)\n",
    "  if best_score < res['test_score'].mean():\n",
    "    best_score = res['test_score'].mean()\n",
    "    best_depth = i\n",
    "print(f\"Наилучая найденная глубина: {best_depth}\")\n",
    "clf = tree.DecisionTreeClassifier(max_depth = best_depth)\n",
    "bagging_clf = BaggingClassifier(clf, n_estimators = 5)\n",
    "bagging_clf = bagging_clf.fit(x_train, y_train)\n",
    "print(f\"Score моей модели = {bagging_clf.score(x_test, y_test)}\")\n",
    "bagging_clf_score = bagging_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5958a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая найденная глубина: 1\n",
      "Score моей модели = 0.5052\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "best_score = 0\n",
    "for i in range(1, 100):\n",
    "  rfc = RandomForestClassifier(max_depth=i, n_estimators=5)\n",
    "  res = cross_validate(rfc, x_train, y_train, cv = cvsk)\n",
    "  if best_score < res['test_score'].mean():\n",
    "    best_score = res['test_score'].mean()\n",
    "    best_depth = i\n",
    "print(f\"Наилучшая найденная глубина: {best_depth}\")\n",
    "rfc = RandomForestClassifier(max_depth = best_depth)\n",
    "rfc.fit(x_train, y_train)\n",
    "print(f\"Score моей модели = {rfc.score(x_test, y_test)}\")\n",
    "rfc_score = rfc.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd42d968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая найденная глубина: 1\n",
      "Score моей модели = 0.5052\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "best_score = 0\n",
    "for i in range(1, 50):\n",
    "  stackingClf = StackingClassifier(\n",
    "    estimators=[\n",
    "      ('t1', tree.DecisionTreeClassifier(max_depth=i)),\n",
    "      ('t2', tree.DecisionTreeClassifier(max_depth=i)),\n",
    "      ('t3', tree.DecisionTreeClassifier(max_depth=i)),\n",
    "      ('t4', tree.DecisionTreeClassifier(max_depth=i)),\n",
    "      ('t5', tree.DecisionTreeClassifier(max_depth=i)),\n",
    "    ],\n",
    "    final_estimator=tree.DecisionTreeClassifier(max_depth=i)\n",
    "  )\n",
    "  res = cross_validate(stackingClf, x_train, y_train, cv = cvsk)\n",
    "  if best_score < res['test_score'].mean():\n",
    "    best_score = res['test_score'].mean()\n",
    "    best_depth = i\n",
    "print(f\"Наилучшая найденная глубина: {best_depth}\")\n",
    "stackingClf = StackingClassifier(\n",
    "    estimators=[\n",
    "      ('t1', tree.DecisionTreeClassifier(max_depth = best_depth)),\n",
    "      ('t2', tree.DecisionTreeClassifier(max_depth = best_depth)),\n",
    "      ('t3', tree.DecisionTreeClassifier(max_depth = best_depth)),\n",
    "      ('t4', tree.DecisionTreeClassifier(max_depth = best_depth)),\n",
    "      ('t5', tree.DecisionTreeClassifier(max_depth = best_depth)),\n",
    "    ],\n",
    "    final_estimator=tree.DecisionTreeClassifier(max_depth = best_depth)\n",
    "  )\n",
    "stackingClf.fit(x_train, y_train)\n",
    "print(f\"Score моей модели = {stackingClf.score(x_test, y_test)}\")\n",
    "stackingClf_score = stackingClf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "116577c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшая найденная глубина: 1\n",
      "Score моей модели = 0.5052\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_depth = 0\n",
    "for i in range(1, 100):\n",
    "  AdaBoost_clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=i), n_estimators=5)\n",
    "  res = cross_validate(AdaBoost_clf, x_train, y_train, cv = cvsk)\n",
    "  if best_score < res['test_score'].mean():\n",
    "    best_score = res['test_score'].mean()\n",
    "    best_depth = i\n",
    "print(f\"Наилучшая найденная глубина: {best_depth}\")\n",
    "AdaBoost_clf = AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=best_depth), n_estimators=5)\n",
    "AdaBoost_clf = AdaBoost_clf.fit(x_train, y_train)\n",
    "print(f\"Score моей модели = {AdaBoost_clf.score(x_test, y_test)}\")\n",
    "AdaBoostClf_score = AdaBoost_clf.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73ec16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все модели показали одинаковый score: 0.5052\n"
     ]
    }
   ],
   "source": [
    "x = {\"AdaBoost\": AdaBoostClf_score, \"Bagging\": bagging_clf_score, \"Random forest\": rfc_score, \"Stacking\": stackingClf_score}\n",
    "scores = list(x.values())\n",
    "if all(score == scores[0] for score in scores):\n",
    "    print(\"Все модели показали одинаковый score:\", scores[0])\n",
    "else:\n",
    "    best_model = max(x, key=x.get)\n",
    "    print(f\"Лучшая модель: {best_model} (score = {x[best_model]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d3eb8",
   "metadata": {},
   "source": [
    "### Я думаю что в результате мы часто получаем скор у всех ансамблевых методов одинаковый, потому что у нас есть шум, который мешает модели хорошо обучиться. И даже увеличение глубины дерева не приводит к улучшению, так как:\n",
    "\n",
    "- В данных всего один признак, и зависимость между $x$ и $y$ довольно простая (синусоида с шумом). Эту зависимость легко аппроксимировать даже деревом глубины 1.\n",
    "- Более сложные деревья не дают прироста, потому что нет дополнительных признаков для ветвления и разделения классов.\n",
    "- Если добавить больше признаков или усложнить зависимость между $x$ и $y$, то ансамбли и глубина деревьев начнут играть большую роль, и результаты моделей будут отличаться.\n",
    "\n",
    "Таким образом, на простых данных с одним признаком ансамблевые методы не дают преимущества, и все модели выбирают минимальную глубину дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530174e9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
